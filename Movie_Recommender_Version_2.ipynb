{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install surprise -q\n",
        "!pip install streamlit -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eu2hLAasWPEc",
        "outputId": "d9aee449-664f-45db-c19d-7977cb62c2cf"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5f7DTjqwCuPu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make Dataset"
      ],
      "metadata": {
        "id": "hc5sLPd9WCcS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MIN_NUM_RATINGS = 1000"
      ],
      "metadata": {
        "id": "kuDG0lEWDNhS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "artifacts_data_processed_path = os.path.join(os.getcwd(),'artifacts/processed/data')\n",
        "if not os.path.exists(artifacts_data_processed_path):\n",
        "    os.makedirs(artifacts_data_processed_path)\n",
        "\n",
        "artifacts_html_processed_path = os.path.join(os.getcwd(),'artifacts/processed/html')\n",
        "if not os.path.exists(artifacts_html_processed_path):\n",
        "    os.makedirs(artifacts_html_processed_path)"
      ],
      "metadata": {
        "id": "rZgqbeyEDPi5"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download dataset\n",
        "\n",
        "!mkdir -p /content/dataset\n",
        "\n",
        "!wget -c \"https://files.grouplens.org/datasets/movielens/ml-25m.zip\" -P /content/dataset\n",
        "\n",
        "!unzip -q \"/content/dataset/ml-25m.zip\" -d /content/dataset\n",
        "\n",
        "# list the files in /content/dataset to verify the download\n",
        "\n",
        "!ls /content/dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8w8dgunFGi8L",
        "outputId": "b886f094-0edf-4bd5-b03f-f3bbfd5c95ef"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-14 18:18:06--  https://files.grouplens.org/datasets/movielens/ml-25m.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 261978986 (250M) [application/zip]\n",
            "Saving to: ‘/content/dataset/ml-25m.zip’\n",
            "\n",
            "ml-25m.zip          100%[===================>] 249.84M  56.1MB/s    in 4.8s    \n",
            "\n",
            "2024-05-14 18:18:12 (51.6 MB/s) - ‘/content/dataset/ml-25m.zip’ saved [261978986/261978986]\n",
            "\n",
            "ml-25m\tml-25m.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def prepare_movies_data(movies, ratings):\n",
        "#     for phrase in ['The', 'An', 'A', 'Les']:\n",
        "#         movies['title'] = [\n",
        "#             f'{phrase} ' + title.replace(f', {phrase}', '') if f', {phrase}' in title else title\n",
        "#             for title in movies.title\n",
        "#         ]\n",
        "#     ratings['rating_scaled'] = ratings['rating'] / 5\n",
        "#     avg_rating_scaled = ratings['rating_scaled'].mean()\n",
        "#     shrinkage_factor = 100\n",
        "\n",
        "#     avg_rating_per_movie = ratings.groupby('movieId').rating_scaled.aggregate(['mean', 'count', 'sum']).reset_index()\n",
        "#     avg_rating_per_movie.columns = ['movieId', 'avg_rating', 'num_ratings', 'total_ratings']\n",
        "#     avg_rating_per_movie['movieId'] = avg_rating_per_movie['movieId'].astype(int)\n",
        "#     avg_rating_per_movie['emp_bayes_rating'] = (\n",
        "#         ((avg_rating_per_movie['avg_rating'] * avg_rating_per_movie['num_ratings']) + (shrinkage_factor * avg_rating_scaled)) /\n",
        "#         (avg_rating_per_movie['num_ratings'] + shrinkage_factor)\n",
        "#     )\n",
        "#     avg_rating_per_movie['smoothed_rating'] = [\n",
        "#     row['emp_bayes_rating'] if row['avg_rating'] > avg_rating_scaled # if the movie has an above average rating => use emp bayes smoothing\n",
        "#     else row['avg_rating'] # if its below average just use that average\n",
        "#         for ix, row in avg_rating_per_movie.iterrows()\n",
        "#     ]\n",
        "#     movies = movies.merge(avg_rating_per_movie, on='movieId')\n",
        "#     movies['title_and_stats'] = (\n",
        "#         movies['title']\n",
        "#         + ' - Rating: ' + (100 * movies['smoothed_rating']).round(0).astype(int).astype(str) + '%'\n",
        "#     )\n",
        "#     movies['year'] = movies.title.str.extract(r'\\((\\d{4})\\)')\n",
        "#     movies['genres_list'] = movies.genres.str.split('|')\n",
        "#     movies = movies[movies['num_ratings'] >= MIN_NUM_RATINGS]\n",
        "#     movies.to_csv(os.path.join(artifacts_data_processed_path,'movies.csv'), index=False)\n",
        "#     return movies"
      ],
      "metadata": {
        "id": "I3NZLcHkGKS4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# movies = prepare_movies_data(movies, ratings)\n",
        "# movies.head()"
      ],
      "metadata": {
        "id": "iFNqsuobGLjb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# movies.shape"
      ],
      "metadata": {
        "id": "nhHQBWGmGqvO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def prepare_movies_data(movies, ratings):\n",
        "#     for phrase in ['The', 'An', 'A', 'Les']:\n",
        "#         movies['title'] = [\n",
        "#             f'{phrase} ' + title.replace(f', {phrase}', '') if f', {phrase}' in title else title\n",
        "#             for title in movies.title\n",
        "#         ]\n",
        "#     ratings['rating_scaled'] = ratings['rating'] / 5\n",
        "#     avg_rating_scaled = ratings['rating_scaled'].mean()\n",
        "#     shrinkage_factor = 100\n",
        "\n",
        "#     avg_rating_per_movie = ratings.groupby('movieId').rating_scaled.aggregate(['mean', 'count', 'sum']).reset_index()\n",
        "#     avg_rating_per_movie.columns = ['movieId', 'avg_rating', 'num_ratings', 'total_ratings']\n",
        "#     avg_rating_per_movie['movieId'] = avg_rating_per_movie['movieId'].astype(int)\n",
        "#     avg_rating_per_movie['emp_bayes_rating'] = (\n",
        "#         ((avg_rating_per_movie['avg_rating'] * avg_rating_per_movie['num_ratings']) + (shrinkage_factor * avg_rating_scaled)) /\n",
        "#         (avg_rating_per_movie['num_ratings'] + shrinkage_factor)\n",
        "#     )\n",
        "#     avg_rating_per_movie['smoothed_rating'] = [\n",
        "#     row['emp_bayes_rating'] if row['avg_rating'] > avg_rating_scaled # if the movie has an above average rating => use emp bayes smoothing\n",
        "#     else row['avg_rating'] # if its below average just use that average\n",
        "#         for ix, row in avg_rating_per_movie.iterrows()\n",
        "#     ]\n",
        "#     movies = movies.merge(avg_rating_per_movie, on='movieId')\n",
        "#     movies['title_and_stats'] = (\n",
        "#         movies['title']\n",
        "#         + ' - Rating: ' + (100 * movies['smoothed_rating']).round(0).astype(int).astype(str) + '%'\n",
        "#     )\n",
        "#     movies['year'] = movies.title.str.extract(r'\\((\\d{4})\\)')\n",
        "#     movies['genres_list'] = movies.genres.str.split('|')\n",
        "#     movies = movies[movies['num_ratings'] >= MIN_NUM_RATINGS]\n",
        "#     movies.to_csv(os.path.join(artifacts_data_processed_path,'movies.csv'), index=False)\n",
        "#     return movies"
      ],
      "metadata": {
        "id": "nl3Ts1XIGtVO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "class MovieProcessor:\n",
        "  \"\"\"\n",
        "  This class processes movie data and ratings to prepare them for further analysis.\n",
        "  \"\"\"\n",
        "  def __init__(self, min_num_ratings):\n",
        "    self.min_num_ratings = min_num_ratings\n",
        "\n",
        "  def process_movies_data(self, movies, ratings):\n",
        "    \"\"\"\n",
        "    This function processes movies data and ratings.\n",
        "\n",
        "    Args:\n",
        "      movies (pandas.DataFrame): A DataFrame containing movie information.\n",
        "      ratings (pandas.DataFrame): A DataFrame containing movie ratings.\n",
        "\n",
        "    Returns:\n",
        "      pandas.DataFrame: A processed DataFrame containing movie information and ratings.\n",
        "    \"\"\"\n",
        "    movies['title'] = self.preprocess_title(movies['title'])\n",
        "    ratings['rating_scaled'] = ratings['rating'] / 5\n",
        "    avg_rating_scaled = ratings['rating_scaled'].mean()\n",
        "    shrinkage_factor = 100\n",
        "\n",
        "    avg_rating_per_movie = ratings.groupby('movieId').rating_scaled.aggregate(['mean', 'count', 'sum']).reset_index()\n",
        "    avg_rating_per_movie.columns = ['movieId', 'avg_rating', 'num_ratings', 'total_ratings']\n",
        "    avg_rating_per_movie['movieId'] = avg_rating_per_movie['movieId'].astype(int)\n",
        "    avg_rating_per_movie['emp_bayes_rating'] = (\n",
        "        ((avg_rating_per_movie['avg_rating'] * avg_rating_per_movie['num_ratings']) + (shrinkage_factor * avg_rating_scaled)) /\n",
        "        (avg_rating_per_movie['num_ratings'] + shrinkage_factor)\n",
        "    )\n",
        "    avg_rating_per_movie['smoothed_rating'] = self.choose_rating(avg_rating_per_movie, avg_rating_scaled)\n",
        "\n",
        "    movies = movies.merge(avg_rating_per_movie, on='movieId')\n",
        "    movies['title_and_stats'] = (\n",
        "        movies['title']\n",
        "        + ' - Rating: ' + (100 * movies['smoothed_rating']).round(0).astype(int).astype(str) + '%'\n",
        "    )\n",
        "\n",
        "    movies['title_and_stats'] = (movies['title'] + ' - Rating: ' + (100 * movies['smoothed_rating']).astype(int).astype(str) + '%')\n",
        "\n",
        "    movies['year'] = movies.title.str.extract(r'\\((\\d{4})\\)')\n",
        "    movies['genres_list'] = movies.genres.str.split('|')\n",
        "    movies = movies[movies['num_ratings'] >= self.min_num_ratings]\n",
        "    return movies\n",
        "\n",
        "  def preprocess_title(self, titles):\n",
        "    \"\"\"\n",
        "    This function preprocesses movie titles by removing articles like \"The\", \"An\", \"A\", and \"Les\".\n",
        "\n",
        "    Args:\n",
        "      titles (pandas.Series): A Series containing movie titles.\n",
        "\n",
        "    Returns:\n",
        "      pandas.Series: A Series containing preprocessed movie titles.\n",
        "    \"\"\"\n",
        "    for phrase in ['The', 'An', 'A', 'Les']:\n",
        "        titles = [\n",
        "            f'{phrase} ' + title.replace(f', {phrase}', '') if f', {phrase}' in title else title\n",
        "            for title in titles\n",
        "        ]\n",
        "    return titles\n",
        "\n",
        "  def choose_rating(self, df, avg_rating_scaled):\n",
        "    \"\"\"\n",
        "    This function chooses between the average rating and the Empiricial Bayesian smoothed rating based on a threshold.\n",
        "\n",
        "    Args:\n",
        "      df (pandas.DataFrame): A DataFrame containing movie information and ratings.\n",
        "      avg_rating_scaled (float): The average rating scaled to a 0-1 range.\n",
        "\n",
        "    Returns:\n",
        "      pandas.Series: A Series containing the chosen rating for each movie.\n",
        "    \"\"\"\n",
        "    return df.apply(lambda row: row['emp_bayes_rating'] if row['avg_rating'] > avg_rating_scaled else row['avg_rating'], axis=1)"
      ],
      "metadata": {
        "id": "DhXt8e5FIfaL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the MovieProcessor class\n",
        "processor = MovieProcessor(MIN_NUM_RATINGS)\n",
        "\n",
        "# Reading Data\n",
        "movie_dataset_path = '/content/dataset/ml-25m/movies.csv'\n",
        "ratings_dataset_path = '/content/dataset/ml-25m/ratings.csv'\n",
        "\n",
        "\n",
        "movies = pd.read_csv(movie_dataset_path)\n",
        "ratings = pd.read_csv(ratings_dataset_path)\n",
        "\n",
        "# Process the movie data and ratings\n",
        "processed_movies = processor.process_movies_data(movies, ratings)\n",
        "\n",
        "# Save the processed data to a CSV file (optional)\n",
        "processed_movies.to_csv(os.path.join(artifacts_data_processed_path,'movies.csv'), index=False)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "XPhUV2T3KINN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "class MovieGenres:\n",
        "    \"\"\"\n",
        "    This class processes movie data to extract genre information.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, movies):\n",
        "        self.movies = movies\n",
        "\n",
        "    def extract_genres(self):\n",
        "        \"\"\"\n",
        "        Extracts genres from the 'genres' column, splits them,\n",
        "        and creates a DataFrame with genre counts.\n",
        "\n",
        "        Returns:\n",
        "            pandas.DataFrame: A DataFrame with columns 'genre' and 'count'.\n",
        "        \"\"\"\n",
        "\n",
        "        genres = self.movies.genres.str.split(\"|\", expand=True)\n",
        "        genres = genres.stack().reset_index(level=1, drop=True).value_counts().reset_index()\n",
        "        genres.columns = [\"genre\", \"count\"]\n",
        "        return genres\n",
        "\n",
        "\n",
        "movie_genres = MovieGenres(processed_movies)\n",
        "genres_df = movie_genres.extract_genres()\n",
        "\n",
        "genres_df.to_csv(os.path.join(artifacts_data_processed_path,'genres.csv'), index=False)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "EllD_TF2XQue"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def extract_genres(movies):\n",
        "#     genres = movies.genres.str.split('|', expand=True)\n",
        "#     genres = (\n",
        "#         genres.stack()\n",
        "#         .reset_index(level=1, drop=True)\n",
        "#         .value_counts()\n",
        "#         .reset_index()\n",
        "#     )\n",
        "#     genres.columns=['genre', 'count']\n",
        "#     genres.to_csv(os.path.join(artifacts_data_processed_path,'genres.csv'))"
      ],
      "metadata": {
        "id": "O2-Wg_2cW43z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_ratings(ratings):\n",
        "    users_sampled = ratings.userId.drop_duplicates().sample(1000, replace=False, random_state=42)\n",
        "    ratings_1k_users = ratings[ratings.userId.isin(users_sampled)]\n",
        "    ratings_1k_users.to_csv(os.path.join(artifacts_data_processed_path,'ratings-1k-users.csv'), index=False)"
      ],
      "metadata": {
        "id": "8IfpI3lUXChO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SampleRatings:\n",
        "    \"\"\"\n",
        "    This class samples a specific number of users and their ratings from a DataFrame.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, ratings, sample_size=1000, random_state=42):\n",
        "        self.ratings = ratings\n",
        "        self.sample_size = sample_size\n",
        "        self.random_state = random_state\n",
        "\n",
        "    def sample_user_ratings(self):\n",
        "        \"\"\"\n",
        "        Samples a specific number of users and their ratings from the DataFrame.\n",
        "\n",
        "        Returns:\n",
        "            pandas.DataFrame: A DataFrame containing sampled user ratings.\n",
        "        \"\"\"\n",
        "\n",
        "        users_sampled = self.ratings.userId.drop_duplicates().sample(\n",
        "            self.sample_size, replace=False, random_state=self.random_state\n",
        "        )\n",
        "        ratings_sampled = self.ratings[self.ratings.userId.isin(users_sampled)]\n",
        "        return ratings_sampled\n",
        "\n",
        "\n",
        "\n",
        "# Create a SampleRatings object and call methods\n",
        "sample_ratings = SampleRatings(ratings,1000,42)\n",
        "\n",
        "# Sample 500 users with random state 20\n",
        "sampled_df = sample_ratings.sample_user_ratings()\n",
        "\n",
        "# Save the sampled ratings to a CSV file\n",
        "sampled_df.to_csv(os.path.join(artifacts_data_processed_path,'ratings-500-users.csv'), index=False)"
      ],
      "metadata": {
        "id": "b_pO6HJRXzrS"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Dataset"
      ],
      "metadata": {
        "id": "s_xYHnlrWSLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from surprise import Dataset, Reader, SVD, KNNWithMeans\n",
        "from surprise.model_selection import cross_validate\n",
        "from scipy.sparse.linalg import svds\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "J94X0rKLQuT6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NEW_USER_ID = -1\n",
        "\n",
        "def create_new_user_ratings(users_favourite_movies: list, movies: pd.DataFrame):\n",
        "    new_user_ratings = pd.DataFrame({\n",
        "        'userId': [NEW_USER_ID] * len(users_favourite_movies),\n",
        "        'movieId': movies[movies.title.isin(users_favourite_movies)].movieId,\n",
        "        'rating': [5] * len(users_favourite_movies),\n",
        "        'rating_scaled': [1.0] * len(users_favourite_movies)\n",
        "    })\n",
        "    return new_user_ratings\n",
        "\n",
        "def train_model(data):\n",
        "    svd = SVD()\n",
        "    svd.fit(data.build_full_trainset())\n",
        "    return svd\n",
        "\n",
        "def eval_model(data):\n",
        "    svd = SVD()\n",
        "    cv = cross_validate(svd, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
        "    return cv\n",
        "\n",
        "def get_estimated_movie_ratings(movies: pd.DataFrame, ratings: pd.DataFrame, users_favourite_movies: list, training_ratings: pd.DataFrame):\n",
        "    new_user_ratings = create_new_user_ratings(users_favourite_movies, movies)\n",
        "    ratings = pd.concat([training_ratings, new_user_ratings], axis=0, ignore_index=True)\n",
        "    reader = Reader(rating_scale=(0.0, 5))\n",
        "    data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
        "    # eval_model(data) # MAE: 0.6568, RMSE: 0.8589\n",
        "    print(eval_model(data))\n",
        "    svd = train_model(data)\n",
        "    predictions = []\n",
        "    for movie in movies.movieId.tolist():\n",
        "        predictions.append(svd.predict(NEW_USER_ID, movie))\n",
        "    movies['predictions'] = predictions\n",
        "    movies['estimated_rating'] = [pred.est for pred in predictions]\n",
        "    movies['estimated_rating'] = movies['estimated_rating'] / 5.0\n",
        "    users_fav_movies = movies[movies.title.isin(users_favourite_movies)]\n",
        "    movies = movies[movies.title.isin(users_favourite_movies) == False]\n",
        "    movies = movies.sort_values('estimated_rating', ascending=False)\n",
        "    return movies\n",
        "\n",
        "\n",
        "users_favourite_movies = [\n",
        "        \"Toy Story (1995)\",\n",
        "        \"The Martian (2015)\",\n",
        "        \"Jumanji (1995)\",\n",
        "        \"Arrival (2016)\",\n",
        "        \"Zootopia (2016)\"\n",
        "    ]\n",
        "ratings = pd.read_csv('/content/artifacts/processed/data/ratings-1k-users.csv')\n",
        "movies = pd.read_csv('/content/artifacts/processed/data/movies.csv')\n",
        "get_estimated_movie_ratings(movies, ratings, users_favourite_movies, ratings).tail()"
      ],
      "metadata": {
        "id": "ec-g287ITxsF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from surprise import Dataset, Reader, SVD, KNNWithMeans\n",
        "from surprise.model_selection import cross_validate\n",
        "from scipy.sparse.linalg import svds\n",
        "import numpy as np\n",
        "\n",
        "NEW_USER_ID = -1\n",
        "\n",
        "\n",
        "class RecommendationEngine:\n",
        "    \"\"\"\n",
        "    This class provides methods for creating new user ratings, training a model,\n",
        "    evaluating the model, and getting estimated movie ratings for a user.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, movies_df, ratings_df):\n",
        "        self.movies_df = movies_df.copy()  # Avoid modifying original DataFrame\n",
        "        self.ratings_df = ratings_df.copy()  # Avoid modifying original DataFrame\n",
        "        self.reader = Reader(rating_scale=(0.0, 5.0))\n",
        "        self.data = None  # Pre-compute data for efficiency\n",
        "\n",
        "    def create_new_user_ratings(self, users_favourite_movies):\n",
        "        \"\"\"\n",
        "        Creates a DataFrame with new user ratings for the user's favourite movies.\n",
        "\n",
        "        Args:\n",
        "            users_favourite_movies (list): A list of movie titles.\n",
        "\n",
        "        Returns:\n",
        "            pandas.DataFrame: A DataFrame containing new user ratings.\n",
        "        \"\"\"\n",
        "\n",
        "        movie_ids = self.movies_df[self.movies_df.title.isin(users_favourite_movies)][\n",
        "            \"movieId\"\n",
        "        ].tolist()\n",
        "        new_user_ratings = pd.DataFrame({\n",
        "            \"userId\": [NEW_USER_ID] * len(movie_ids),\n",
        "            \"movieId\": movie_ids,\n",
        "            \"rating\": [5] * len(movie_ids),\n",
        "            \"rating_scaled\": [1.0] * len(movie_ids),\n",
        "        })\n",
        "        return new_user_ratings\n",
        "\n",
        "    def train_model(self, data):\n",
        "        \"\"\"\n",
        "        Trains an SVD model on the provided dataset.\n",
        "\n",
        "        Args:\n",
        "            data (surprise.Dataset): The dataset to train the model on.\n",
        "\n",
        "        Returns:\n",
        "            surprise.SVD: The trained SVD model.\n",
        "        \"\"\"\n",
        "\n",
        "        svd = SVD()\n",
        "        svd.fit(data.build_full_trainset())\n",
        "        return svd\n",
        "\n",
        "    def eval_model(self, data):\n",
        "        \"\"\"\n",
        "        Evaluates the performance of an SVD model using cross-validation.\n",
        "\n",
        "        Args:\n",
        "            data (surprise.Dataset): The dataset to evaluate the model on.\n",
        "\n",
        "        Returns:\n",
        "            dict: The cross-validation results.\n",
        "        \"\"\"\n",
        "\n",
        "        if self.data is None:\n",
        "            self.data = Dataset.load_from_df(\n",
        "                self.ratings_df[[\"userId\", \"movieId\", \"rating\"]], self.reader\n",
        "            )\n",
        "        svd = SVD()\n",
        "        cv = cross_validate(svd, self.data, measures=[\"RMSE\", \"MAE\"], cv=5, verbose=True)\n",
        "        return cv\n",
        "\n",
        "    def get_estimated_movie_ratings(self, users_favourite_movies):\n",
        "        \"\"\"\n",
        "        Recommends movies for a user based on their favourite movies.\n",
        "\n",
        "        Args:\n",
        "            users_favourite_movies (list): A list of movie titles.\n",
        "\n",
        "        Returns:\n",
        "            pandas.DataFrame: A DataFrame containing movies sorted by estimated rating.\n",
        "        \"\"\"\n",
        "\n",
        "        new_user_ratings = self.create_new_user_ratings(users_favourite_movies)\n",
        "        ratings = pd.concat([self.ratings_df, new_user_ratings], axis=0, ignore_index=True)\n",
        "        data = Dataset.load_from_df(ratings[[\"userId\", \"movieId\", \"rating\"]], self.reader)\n",
        "\n",
        "        print(self.eval_model(data))\n",
        "        svd = self.train_model(data)\n",
        "\n",
        "        # Vectorize movie IDs for faster prediction\n",
        "        movie_ids = self.movies_df[\"movieId\"].tolist()\n",
        "        predictions = []\n",
        "        for movie in movies.movieId.tolist():\n",
        "            predictions.append(svd.predict(NEW_USER_ID, movie))\n",
        "        self.movies_df[\"predictions\"] = predictions\n",
        "        self.movies_df[\"estimated_rating\"] = [pred.est for pred in predictions]\n",
        "        self.movies_df[\"estimated_rating\"] /= 5.0\n",
        "\n",
        "        users_fav_movies = self.movies_df[self.movies_df.title.isin(users_favourite_movies)]\n",
        "        other_movies = self.movies_df[self.movies_df.title.isin(users_favourite_movies) == False]\n",
        "        recommended_movies = other_movies.sort_values(by=\"estimated_rating\", ascending=False)\n",
        "\n",
        "        return recommended_movies.tail()\n",
        "\n",
        "\n",
        "# Create movie and rating DataFrames (assuming you have these loaded)\n",
        "users_favourite_movies = [\n",
        "        \"Toy Story (1995)\",\n",
        "        \"The Martian (2015)\",\n",
        "        \"Jumanji (1995)\",\n",
        "        \"Arrival (2016)\",\n",
        "        \"Zootopia (2016)\"\n",
        "    ]\n",
        "ratings = pd.read_csv('/content/artifacts/processed/data/ratings-500-users.csv')\n",
        "movies = pd.read_csv('/content/artifacts/processed/data/movies.csv')\n",
        "recommendation_engine = RecommendationEngine(movies, ratings)\n",
        "recommended_movies = recommendation_engine.get_estimated_movie_ratings(users_favourite_movies)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sN0_4arWXoQ",
        "outputId": "f28539c7-ecdd-4792-848d-75eb2f7c4884"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "RMSE (testset)    0.8902  0.8931  0.8937  0.8863  0.8883  0.8903  0.0028  \n",
            "MAE (testset)     0.6851  0.6867  0.6866  0.6831  0.6834  0.6850  0.0015  \n",
            "Fit time          2.21    2.32    2.93    2.32    2.27    2.41    0.26    \n",
            "Test time         0.38    0.36    0.32    0.19    0.36    0.32    0.07    \n",
            "{'test_rmse': array([0.89015558, 0.89307383, 0.89371781, 0.88632892, 0.88834473]), 'test_mae': array([0.68510241, 0.68667115, 0.68656707, 0.68312179, 0.68337901]), 'fit_time': (2.2061471939086914, 2.3239073753356934, 2.9311740398406982, 2.3174846172332764, 2.2723891735076904), 'test_time': (0.38335132598876953, 0.36094045639038086, 0.31877899169921875, 0.18884873390197754, 0.35735011100769043)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "from surprise import Dataset, Reader, SVD, KNNWithMeans\n",
        "import pandas as pd\n",
        "from surprise.model_selection import cross_validate\n",
        "from scipy.sparse.linalg import svds\n",
        "import numpy as np\n",
        "\n",
        "NEW_USER_ID = -1\n",
        "\n",
        "def create_new_user_ratings(users_favourite_movies: list, movies: pd.DataFrame):\n",
        "    new_user_ratings = pd.DataFrame({\n",
        "        'userId': [NEW_USER_ID] * len(users_favourite_movies),\n",
        "        'movieId': movies[movies.title.isin(users_favourite_movies)].movieId,\n",
        "        'rating': [5] * len(users_favourite_movies),\n",
        "        'rating_scaled': [1.0] * len(users_favourite_movies)\n",
        "    })\n",
        "    return new_user_ratings\n",
        "\n",
        "def train_model(data):\n",
        "    svd = SVD()\n",
        "    svd.fit(data.build_full_trainset())\n",
        "    return svd\n",
        "\n",
        "def eval_model(data):\n",
        "    svd = SVD()\n",
        "    cv = cross_validate(svd, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
        "    return cv\n",
        "\n",
        "def get_estimated_movie_ratings(movies: pd.DataFrame, ratings: pd.DataFrame, users_favourite_movies: list, training_ratings: pd.DataFrame):\n",
        "    new_user_ratings = create_new_user_ratings(users_favourite_movies, movies)\n",
        "    ratings = pd.concat([training_ratings, new_user_ratings], axis=0, ignore_index=True)\n",
        "    reader = Reader(rating_scale=(0.0, 5))\n",
        "    data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
        "    svd = train_model(data)\n",
        "    predictions = []\n",
        "    for movie in movies.movieId.tolist():\n",
        "        predictions.append(svd.predict(NEW_USER_ID, movie))\n",
        "    movies['predictions'] = predictions\n",
        "    movies['estimated_rating'] = [pred.est for pred in predictions]\n",
        "    movies['estimated_rating'] = movies['estimated_rating'] / 5.0\n",
        "    users_fav_movies = movies[movies.title.isin(users_favourite_movies)]\n",
        "    movies = movies[movies.title.isin(users_favourite_movies) == False]\n",
        "    movies = movies.sort_values('estimated_rating', ascending=False)\n",
        "    return movies\n",
        "\n",
        "movies = pd.read_csv('/content/artifacts/processed/data/movies.csv')\n",
        "genres = pd.read_csv('/content/artifacts/processed/data/genres.csv')\n",
        "movies.sort_values('smoothed_rating', ascending=False, inplace=True)\n",
        "ratings = pd.read_csv('/content/artifacts/processed/data/ratings-500-users.csv')\n",
        "\n",
        "st.set_page_config(\n",
        "    page_title=\"Movie Recommender\",\n",
        "    page_icon=\"🎥\",\n",
        "    layout=\"wide\"\n",
        ")\n",
        "st.title('🎥 Movie Recommender')\n",
        "st.caption('Choose Any movies you liked or watched previously! 🍿')\n",
        "\n",
        "with st.form(key='my_form'):\n",
        "    selected_movies = st.multiselect(\n",
        "        '✅ Choose more than one movies you like',\n",
        "        options=movies.title_and_stats.tolist(),\n",
        "        help='Type initials of any movie name in order to view the list of movies to select from!'\n",
        "    )\n",
        "    with st.expander('Filtering Options', expanded=False):\n",
        "        col1, col2 = st.columns(2)\n",
        "        with col1:\n",
        "            year_range = st.slider('Year Range', min_value=1900, max_value=2018, value=(1970, 2018))\n",
        "        with col2:\n",
        "            selected_genres = st.multiselect(\n",
        "                'Genre(s)',\n",
        "                genres.genre.tolist(),\n",
        "                help='If you start typing the name of a genre, the list will be filtered accordingly for you to pick from.'\n",
        "            )\n",
        "    submit_button = st.form_submit_button(\n",
        "        label='Find similar Movies!!',\n",
        "        type='primary'\n",
        "    )\n",
        "\n",
        "    if submit_button:\n",
        "        with st.spinner('Finding similar movies...'):\n",
        "            estimated_ratings = get_estimated_movie_ratings(\n",
        "                movies=movies,\n",
        "                ratings=ratings,\n",
        "                users_favourite_movies=movies[movies.title_and_stats.isin(selected_movies)].title.tolist(),\n",
        "                training_ratings=ratings\n",
        "            )\n",
        "            filtered_estimated_ratings = estimated_ratings[\n",
        "                (estimated_ratings.year.between(year_range[0], year_range[1]))\n",
        "            ]\n",
        "            filtered_estimated_ratings = filtered_estimated_ratings[~filtered_estimated_ratings.title.isin(selected_movies)]\n",
        "            if len(selected_genres) > 0:\n",
        "                filtered_estimated_ratings['genre_isin'] = filtered_estimated_ratings['genres_list'].apply(lambda x: any([genre in x for genre in selected_genres]))\n",
        "                filtered_estimated_ratings = filtered_estimated_ratings[filtered_estimated_ratings.genre_isin]\n",
        "            filtered_estimated_ratings['your_rating'] =  100 * filtered_estimated_ratings['estimated_rating']\n",
        "            filtered_estimated_ratings['avg_rating'] = 100 * filtered_estimated_ratings['smoothed_rating']\n",
        "            # filtered_estimated_ratings.index = range(1, filtered_estimated_ratings.shape[0]+1)\n",
        "            st.dataframe(\n",
        "                filtered_estimated_ratings[['title', 'your_rating', 'avg_rating', 'genres', 'num_ratings']].head(100),\n",
        "                column_config={\n",
        "                        \"title\": st.column_config.TextColumn(\n",
        "                            \"Title\", width=\"large\"\n",
        "                        ),\n",
        "                        \"your_rating\": st.column_config.ProgressColumn(\n",
        "                            \"Rating (for you)\",\n",
        "                            format=\"%.0f%%\", width=\"medium\",\n",
        "                            min_value=0,\n",
        "                            max_value=100,\n",
        "                        ),\n",
        "                        \"avg_rating\": st.column_config.NumberColumn(\n",
        "                            \"Average Rating (all users)\",\n",
        "                            format=\"%.0f%%\", width=\"medium\",\n",
        "                        ),\n",
        "                        \"num_ratings\": st.column_config.NumberColumn(\n",
        "                            \"# of Ratings\",\n",
        "                            format=\"%.0f\", width=\"medium\",\n",
        "                        ),\n",
        "                        \"genres\": st.column_config.TextColumn(\n",
        "                            \"Genres\", width=\"large\"\n",
        "                        ),\n",
        "                }\n",
        "\n",
        "            )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAnZ6b4zaEtD",
        "outputId": "0360634a-7c6a-457d-d1e5-855e3adbca55"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zi0qE01TdEaU",
        "outputId": "0f3285b5-4319-418c-f6fd-d03771825334"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "104.199.124.45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run /content/app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuT2ZIDBdJtD",
        "outputId": "665b3d98-88af-4cb0-94fa-1e493b63fcb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://104.199.124.45:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 4.204s\n",
            "your url is: https://vast-clouds-burn.loca.lt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O6PQjrcLdKWo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}